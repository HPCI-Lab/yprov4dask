from dask.order import order
from dask.task_spec import DataNode, Task
from dask.typing import Key
from distributed.diagnostics.plugin import SchedulerPlugin
from distributed.scheduler import Scheduler, TaskState, TaskStateState as SchedulerTaskState
from prov_tracking.documenter import Documenter
from prov_tracking.utils import RunnableTaskInfo

import datetime as dt
from typing import Any
from traceback import format_exc

class ProvTracker(SchedulerPlugin):
  """Provenance tracking plugin"""

  def __init__(self, **kwargs):
    """Additional arguments:
    - `keep_traceback: bool`: tells if the plugin should register the traceback
    of the exceptions generated by failed tasks. Defaults to `False`.
    You can also provide any additional argument accepted by
    `pro_tracking.Documenter`.
    """

    # kwargs that are only used by the plugin, should be removed because some
    # methods used by libraries, unpack kwargs and any additional argument would
    # cause an exception
    self.keep_traceback: bool = kwargs.pop('keep_traceback', False)
    self.documenter = Documenter(**kwargs)
    self.kwargs: dict[str, Any] = kwargs
    self.closed = False
    # Used to avoid registering multiple times the same task. A task can be put
    # multiple times in waiting state
    self.registered_tasks: set[Key] = set()
    # Keeps info about all tasks encountered
    self.all_tasks: dict[Key, Task | DataNode] = {}
    self.non_runnables: dict[Key, DataNode] = {}
    self.all_runnables: dict[Key, RunnableTaskInfo] = {}
    self.macro_tasks: dict[Key, list[Key]] = {}

  def start(self, scheduler: Scheduler):
    self._scheduler = scheduler

  def transition(
    self, key: Key, start: SchedulerTaskState, finish: SchedulerTaskState,
    *args, **kwargs
  ):
    try:
      task = self._scheduler.tasks[key]

      # A new task has been created: register the activity and its data
      if start == 'waiting' and key not in self.registered_tasks:
        # This is a never-seen-before task. Register it as an entity if it is a
        # non-runnable task. Otherwise, register its info are registered in an 
        # internal structure that will be saved as an activity later on.

        self.registered_tasks.add(key)
        if isinstance(task.run_spec, DataNode):
          self.documenter.register_non_runnable_task(str(key), task.run_spec)
          self.non_runnables[key] = task.run_spec
          self.all_tasks[key] = task.run_spec
        elif isinstance(task.run_spec, Task):
          if not ProvTracker._is_dask_internal(task.run_spec):
            self.all_runnables[key] = RunnableTaskInfo(task)
            self.all_tasks[key] = task.run_spec
            self.macro_tasks[key] = [key]
          else:
            infos = self._track_dask_internal(task.run_spec, task.group_key)
            self.all_runnables.update(infos)
            self.macro_tasks[key] = [sub_key for sub_key in infos]
        else:
          # This task is an alias for another task that calls _execute_subgraph
          pass

      elif start == 'processing' and key in self.macro_tasks:
        now = dt.datetime.now()
        for sub_key in self.macro_tasks[key]:
          info = self.all_runnables[sub_key]
          info.start_time = now

      elif start == 'memory' and key in self.macro_tasks:
        now = dt.datetime.now()
        for sub_key in self.macro_tasks[key][:-1]:
          info = self.all_runnables[sub_key]
          info.finish_time = now
          self.documenter.register_successful_task(info, None, None)
        dtype = task.type
        nbytes = task.nbytes
        info = self.all_runnables[self.macro_tasks[key][-1]]
        info.finish_time = now
        self.documenter.register_successful_task(info, dtype, nbytes)

      elif start == 'erred' and key in self.macro_tasks:
        now = dt.datetime.now()
        for sub_key in self.macro_tasks[key][:-1]:
          info = self.all_runnables[sub_key]
          info.finish_time = now
          self.documenter.register_failed_task(info, None, None, None)
        # The task is finished with an error, so register the exception
        info = self.all_runnables[self.macro_tasks[key][-1]]
        info.finish_time = now
        text = task.exception_text or ''
        blamed_task = task.exception_blame
        traceback = None
        if self.keep_traceback:
          traceback = task.traceback_text
        self.documenter.register_failed_task(info, text, traceback, blamed_task)

        # When an exception occurs, the plugin is closed before it has the chance
        # to detect the erred task and register its information. So, if the plugin
        # has already been closed, serialize the document again.
        if self.closed:
          self.documenter.serialize()
    except Exception:
      print(f'Task {key} generated an exception:\n{format_exc()}')

  async def close(self):
    self.closed = True

    try:
      self.documenter.serialize()
    except Exception as e:
      print(f'Close: {e}')

  @staticmethod
  def _is_dask_internal(run_spec: Task) -> bool:
    func = run_spec.func
    if hasattr(func, '__name__'):
      return (
        func.__name__ == '_execute_subgraph' and
        func.__module__ == 'dask._task_spec'
      )
    return False

  def _track_dask_internal(self, run_spec: Task, group_key: str, parent_deps: dict[Key, Any] = {}) -> dict[Key, RunnableTaskInfo]:
    inner_dsk = run_spec.args[0]
    
    # Some dependencies are referenced with names in inkeys that might be
    # different from names already used before for the same resource
    inkeys = run_spec.args[2]
    dependencies = run_spec.args[3:]
    internal_deps: dict[Key, Any] = {}
    for key, dep in zip(inkeys, dependencies):
      if isinstance(dep, DataNode):
        # Create the entity for the datanode
        # Forge a custom key to avoid duplicates
        custom_key = f'{run_spec.key}.key'
        self.documenter.register_non_runnable_task(custom_key, dep)
        internal_deps[key] = DataNode(custom_key, dep.value)
      else:
        # dep is a TaskRef
        internal_deps[key] = self.all_tasks[dep.key]
    
    priorities = order(inner_dsk)
    infos: dict[Key, RunnableTaskInfo] = {}
    for key, node in sorted(inner_dsk.items(), key=lambda it: priorities[it[0]]):
      if isinstance(node, Task):
        self.all_tasks[key] = node
        if ProvTracker._is_dask_internal(node):
          print(f'{group_key}:{run_spec.key} -> Recursion on {node.key}')
          infos.update(self._track_dask_internal(node, group_key, internal_deps))
        else:
          node_deps = []
          for dep in node.dependencies:
            if dep in self._scheduler.tasks:
              node_deps.append((dep, self._scheduler.tasks[dep].run_spec))
            elif dep in inner_dsk:
              node_deps.append((dep, inner_dsk[dep]))
            elif dep in internal_deps:
              node_deps.append((dep, internal_deps[dep]))
          infos[key] = RunnableTaskInfo(
            specs=node, group_key=group_key, dependencies=node_deps
          )
      else:
        self.all_tasks[key] = self.all_tasks[node.target]
        if node.target in infos:
          infos[key] = infos[node.target]
        else:
          infos[key] = self.all_runnables[node.target] # type: ignore
    
    return infos
